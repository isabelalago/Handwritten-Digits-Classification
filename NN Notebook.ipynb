{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extension to reload modules before cell execution\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll test the sigmoid function, and compare it to scipy's implementation to make sure we're getting the right return values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnScript import sigmoid # our sigmoid\n",
    "from scipy.special import expit # scipy's sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7310585786300049\n",
      "0.7310585786300049\n"
     ]
    }
   ],
   "source": [
    "# these should be the same\n",
    "print(sigmoid(1))\n",
    "print(expit(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.linspace(-10,10,100):\n",
    "    assert(sigmoid(i) == expit(i)) # this shouldn't fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It Successfully Failed :D\n"
     ]
    }
   ],
   "source": [
    "# for sanity check\n",
    "try:\n",
    "    assert(sigmoid(0.7) == expit(0.71)) # this should fail\n",
    "except AssertionError as e:\n",
    "    print(\"It Successfully Failed :D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6791787  0.57444252 0.36354746 0.50249998]\n",
      "[0.6791787  0.57444252 0.36354746 0.50249998]\n",
      "Are they equal? [ True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "# checking vector values\n",
    "v = np.array([0.75, 0.3, -0.56, 0.01]) # random vector\n",
    "print(sigmoid(v))\n",
    "print(expit(v))\n",
    "print(\"Are they equal?\", sigmoid(v) == expit(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll test the preprocess function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess():\n",
    "    \"\"\" Input:\n",
    "     Although this function doesn't have any input, you are required to load\n",
    "     the MNIST data set from file 'mnist_all.mat'.\n",
    "\n",
    "     Output:\n",
    "     train_data: matrix of training set. Each row of train_data contains \n",
    "       feature vector of a image\n",
    "     train_label: vector of label corresponding to each image in the training\n",
    "       set\n",
    "     validation_data: matrix of training set. Each row of validation_data \n",
    "       contains feature vector of a image\n",
    "     validation_label: vector of label corresponding to each image in the \n",
    "       training set\n",
    "     test_data: matrix of training set. Each row of test_data contains \n",
    "       feature vector of a image\n",
    "     test_label: vector of label corresponding to each image in the testing\n",
    "       set\n",
    "\n",
    "     Some suggestions for preprocessing step:\n",
    "     - feature selection\"\"\"\n",
    "\n",
    "    mat = loadmat('mnist_all.mat')  # loads the MAT object as a Dictionary\n",
    "\n",
    "    # Pick a reasonable size for validation data\n",
    "\n",
    "    # ------------Initialize preprocess arrays----------------------#\n",
    "    train_preprocess = np.zeros(shape=(50000, 784))\n",
    "    validation_preprocess = np.zeros(shape=(10000, 784))\n",
    "    test_preprocess = np.zeros(shape=(10000, 784))\n",
    "    train_label_preprocess = np.zeros(shape=(50000,))\n",
    "    validation_label_preprocess = np.zeros(shape=(10000,))\n",
    "    test_label_preprocess = np.zeros(shape=(10000,))\n",
    "    # ------------Initialize flag variables----------------------#\n",
    "    train_len = 0\n",
    "    validation_len = 0\n",
    "    test_len = 0\n",
    "    train_label_len = 0\n",
    "    validation_label_len = 0\n",
    "    # ------------Start to split the data set into 6 arrays-----------#\n",
    "    for key in mat:\n",
    "        # -----------when the set is training set--------------------#\n",
    "        if \"train\" in key:\n",
    "            label = key[-1]  # record the corresponding label\n",
    "            tup = mat.get(key)\n",
    "            sap = range(tup.shape[0])\n",
    "            tup_perm = np.random.permutation(sap)\n",
    "            tup_len = len(tup)  # get the length of current training set\n",
    "            tag_len = tup_len - 1000  # defines the number of examples which will be added into the training set\n",
    "\n",
    "            # ---------------------adding data to training set-------------------------#\n",
    "            train_preprocess[train_len:train_len + tag_len] = tup[tup_perm[1000:], :]\n",
    "            train_len += tag_len\n",
    "\n",
    "            train_label_preprocess[train_label_len:train_label_len + tag_len] = label\n",
    "            train_label_len += tag_len\n",
    "\n",
    "            # ---------------------adding data to validation set-------------------------#\n",
    "            validation_preprocess[validation_len:validation_len + 1000] = tup[tup_perm[0:1000], :]\n",
    "            validation_len += 1000\n",
    "\n",
    "            validation_label_preprocess[validation_label_len:validation_label_len + 1000] = label\n",
    "            validation_label_len += 1000\n",
    "\n",
    "            # ---------------------adding data to test set-------------------------#\n",
    "        elif \"test\" in key:\n",
    "            label = key[-1]\n",
    "            tup = mat.get(key)\n",
    "            sap = range(tup.shape[0])\n",
    "            tup_perm = np.random.permutation(sap)\n",
    "            tup_len = len(tup)\n",
    "            test_label_preprocess[test_len:test_len + tup_len] = label\n",
    "            test_preprocess[test_len:test_len + tup_len] = tup[tup_perm]\n",
    "            test_len += tup_len\n",
    "            # ---------------------Shuffle,double and normalize-------------------------#\n",
    "    train_size = range(train_preprocess.shape[0])\n",
    "    train_perm = np.random.permutation(train_size)\n",
    "    train_data = train_preprocess[train_perm]\n",
    "    train_data = np.double(train_data)\n",
    "    train_data = train_data / 255.0\n",
    "    train_label = train_label_preprocess[train_perm]\n",
    "\n",
    "    validation_size = range(validation_preprocess.shape[0])\n",
    "    vali_perm = np.random.permutation(validation_size)\n",
    "    validation_data = validation_preprocess[vali_perm]\n",
    "    validation_data = np.double(validation_data)\n",
    "    validation_data = validation_data / 255.0\n",
    "    validation_label = validation_label_preprocess[vali_perm]\n",
    "\n",
    "    test_size = range(test_preprocess.shape[0])\n",
    "    test_perm = np.random.permutation(test_size)\n",
    "    test_data = test_preprocess[test_perm]\n",
    "    test_data = np.double(test_data)\n",
    "    test_data = test_data / 255.0\n",
    "    test_label = test_label_preprocess[test_perm]\n",
    "\n",
    "    # Feature selection\n",
    "    # Your code here.\n",
    "\n",
    "    print('preprocess done')\n",
    "\n",
    "    return train_data, train_label, validation_data, validation_label, test_data, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592\n",
      "674\n",
      "595\n",
      "613\n",
      "584\n",
      "542\n",
      "591\n",
      "626\n",
      "585\n",
      "594\n",
      "preprocess done\n"
     ]
    }
   ],
   "source": [
    "train_data, train_label, validation_data, validation_label, test_data, test_label = preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now loaded what would normally be the returned data of preprocess() to the above variables.  Now we want to figure out a way to check if a value is the same accross all rows for a given column.\n",
    "\n",
    "Since the algorthm will only be trained on 'train_data', we should only have to test this on that set of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       ...,\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/14859458/how-to-check-if-all-values-in-the-columns-of-a-numpy-matrix-are-the-same\n",
    "(train_data == train_data[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True  True  True  True  True  True  True  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False  True  True\n",
      "  True  True  True  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False  True  True  True  True  True False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False  True  True  True  True False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False  True\n",
      "  True False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False  True\n",
      "  True False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False  True  True  True  True False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False  True  True\n",
      "  True  True False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True  True False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False  True  True  True False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False  True\n",
      "  True  True False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False  True  True  True False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False  True  True  True False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False  True  True\n",
      "  True  True False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False  True  True  True  True  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False  True  True  True  True  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False  True  True  True  True\n",
      "  True  True  True  True  True False False False False False False False\n",
      " False False False False False False False False False False False  True\n",
      "  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "res = np.all(train_data == train_data[0,:], axis = 0)\n",
    "print(len(res)) # 784 == 28 x 28\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is a vector of size 784 indicating `True` if the column is the same for all rows and `False` otherwise.  So, any column that is `True` here is giving us the same value accross the every training example.\n",
    "\n",
    "To make sure we're doing this correctly, we'll perform a similar check in a more intuitive, but disgusting inefficient way.  We see in the above example that the first entry is `True`, meaning that every row should share the same value (either `1` or `0`).\n",
    "\n",
    "So, we'll loop through every example and check if an entry is the same in every row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This one's right\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "\n",
    "# 0th Entry is True\n",
    "t0 = train_data[0][0]\n",
    "for t in train_data:\n",
    "    if (t0 != t[0]):\n",
    "        print(\"Something's wrong\") # shouldn't print\n",
    "        \n",
    "# 100th Entry is True\n",
    "t0 = train_data[0][100]\n",
    "for t in train_data:\n",
    "    if (t0 != t[100]):\n",
    "        print(\"This one's right\") # should print\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 True 0.0\n",
      "1 True 0.0\n",
      "2 True 0.0\n",
      "3 True 0.0\n",
      "4 True 0.0\n",
      "5 True 0.0\n",
      "6 True 0.0\n",
      "7 True 0.0\n",
      "8 True 0.0\n",
      "9 True 0.0\n",
      "10 True 0.0\n",
      "11 True 0.0\n",
      "12 True 0.0\n",
      "13 True 0.0\n",
      "14 True 0.0\n",
      "15 True 0.0\n",
      "16 True 0.0\n",
      "17 True 0.0\n",
      "18 True 0.0\n",
      "19 True 0.0\n",
      "20 True 0.0\n",
      "21 True 0.0\n",
      "22 True 0.0\n",
      "23 True 0.0\n",
      "24 True 0.0\n",
      "25 True 0.0\n",
      "26 True 0.0\n",
      "27 True 0.0\n",
      "28 True 0.0\n",
      "29 True 0.0\n",
      "30 True 0.0\n",
      "31 True 0.0\n",
      "32 True 0.0\n",
      "33 True 0.0\n",
      "34 True 0.0\n",
      "35 False 0.37254901960784315\n",
      "36 False 1.5176470588235293\n",
      "37 False 1.0588235294117647\n",
      "38 False 1.0235294117647058\n",
      "39 False 1.3176470588235294\n",
      "40 False 1.3607843137254902\n",
      "41 False 1.3764705882352941\n",
      "42 False 2.603921568627451\n",
      "43 False 2.3568627450980393\n",
      "44 False 3.384313725490196\n",
      "45 False 4.349019607843138\n",
      "46 False 2.0470588235294116\n",
      "47 False 0.6509803921568628\n",
      "48 False 0.043137254901960784\n",
      "49 False 0.5764705882352941\n",
      "50 False 0.7215686274509804\n",
      "51 False 0.058823529411764705\n",
      "52 True 0.0\n",
      "53 True 0.0\n",
      "54 True 0.0\n",
      "55 True 0.0\n",
      "56 True 0.0\n",
      "57 True 0.0\n",
      "58 True 0.0\n",
      "59 True 0.0\n",
      "60 False 0.6039215686274509\n",
      "61 False 0.32156862745098036\n",
      "62 False 1.5568627450980392\n",
      "63 False 4.6078431372549025\n",
      "64 False 6.0627450980392155\n",
      "65 False 9.27058823529412\n",
      "66 False 13.894117647058822\n",
      "67 False 19.56078431372549\n",
      "68 False 30.99607843137255\n",
      "69 False 44.54901960784318\n",
      "70 False 54.674509803921595\n",
      "71 False 66.86666666666665\n",
      "72 False 75.99607843137254\n",
      "73 False 71.16862745098038\n",
      "74 False 62.968627450980385\n",
      "75 False 47.51764705882354\n",
      "76 False 24.53725490196079\n",
      "77 False 9.737254901960783\n",
      "78 False 4.784313725490196\n",
      "79 False 2.152941176470588\n",
      "80 False 0.5529411764705883\n",
      "81 False 0.03529411764705882\n",
      "82 True 0.0\n",
      "83 True 0.0\n",
      "84 True 0.0\n",
      "85 True 0.0\n",
      "86 True 0.0\n",
      "87 True 0.0\n",
      "88 False 0.2392156862745098\n",
      "89 False 1.7607843137254902\n",
      "90 False 4.776470588235294\n",
      "91 False 12.843137254901961\n",
      "92 False 21.184313725490192\n",
      "93 False 39.682352941176504\n",
      "94 False 64.73333333333335\n",
      "95 False 99.8352941176471\n",
      "96 False 139.6627450980394\n",
      "97 False 191.37254901960802\n",
      "98 False 235.74901960784337\n",
      "99 False 274.2784313725494\n",
      "100 False 277.1764705882355\n",
      "101 False 250.46274509803962\n",
      "102 False 200.54509803921576\n",
      "103 False 140.33333333333337\n",
      "104 False 83.09411764705887\n",
      "105 False 42.89019607843135\n",
      "106 False 19.474509803921563\n",
      "107 False 8.125490196078431\n",
      "108 False 3.8980392156862744\n",
      "109 False 0.7333333333333333\n",
      "110 True 0.0\n",
      "111 True 0.0\n",
      "112 True 0.0\n",
      "113 True 0.0\n",
      "114 True 0.0\n",
      "115 False 0.3764705882352941\n",
      "116 False 1.8\n",
      "117 False 8.176470588235293\n",
      "118 False 20.262745098039215\n",
      "119 False 48.44705882352943\n",
      "120 False 91.40784313725497\n",
      "121 False 169.25882352941196\n",
      "122 False 261.73333333333375\n",
      "123 False 381.4039215686277\n",
      "124 False 535.8549019607851\n",
      "125 False 708.84705882353\n",
      "126 False 831.4000000000021\n",
      "127 False 917.8470588235303\n",
      "128 False 879.6235294117656\n",
      "129 False 779.8901960784314\n",
      "130 False 631.2901960784335\n",
      "131 False 442.27450980392183\n",
      "132 False 290.7568627450985\n",
      "133 False 179.60392156862738\n",
      "134 False 94.37254901960793\n",
      "135 False 44.69803921568627\n",
      "136 False 19.027450980392153\n",
      "137 False 4.356862745098039\n",
      "138 False 0.058823529411764705\n",
      "139 True 0.0\n",
      "140 True 0.0\n",
      "141 True 0.0\n",
      "142 True 0.0\n",
      "143 False 1.4862745098039214\n",
      "144 False 7.219607843137254\n",
      "145 False 28.329411764705878\n",
      "146 False 64.74901960784314\n",
      "147 False 132.72549019607857\n",
      "148 False 246.85490196078473\n",
      "149 False 406.07058823529474\n",
      "150 False 598.7921568627457\n",
      "151 False 859.8745098039234\n",
      "152 False 1173.843137254905\n",
      "153 False 1459.6196078431403\n",
      "154 False 1697.2666666666767\n",
      "155 False 1811.0235294117704\n",
      "156 False 1779.1215686274581\n",
      "157 False 1588.80784313726\n",
      "158 False 1316.5647058823565\n",
      "159 False 973.6000000000024\n",
      "160 False 683.6352941176476\n",
      "161 False 446.6000000000007\n",
      "162 False 270.93333333333374\n",
      "163 False 136.9372549019608\n",
      "164 False 50.678431372549\n",
      "165 False 11.898039215686271\n",
      "166 False 1.5529411764705883\n",
      "167 True 0.0\n",
      "168 True 0.0\n",
      "169 False 0.01568627450980392\n",
      "170 False 0.058823529411764705\n",
      "171 False 3.4078431372549023\n",
      "172 False 17.952941176470585\n",
      "173 False 64.31764705882355\n",
      "174 False 143.34117647058827\n",
      "175 False 275.2588235294119\n",
      "176 False 463.0196078431385\n",
      "177 False 707.4235294117653\n",
      "178 False 1015.3372549019622\n",
      "179 False 1385.5529411764744\n",
      "180 False 1748.709803921573\n",
      "181 False 2076.5333333333456\n",
      "182 False 2337.2509803921675\n",
      "183 False 2452.9725490196265\n",
      "184 False 2407.8392156862847\n",
      "185 False 2219.294117647071\n",
      "186 False 1908.7843137254981\n",
      "187 False 1484.8431372549055\n",
      "188 False 1066.9882352941208\n",
      "189 False 716.1215686274517\n",
      "190 False 429.03137254901947\n",
      "191 False 229.3568627450984\n",
      "192 False 101.36470588235296\n",
      "193 False 35.2156862745098\n",
      "194 False 8.333333333333332\n",
      "195 False 0.3058823529411765\n",
      "196 True 0.0\n",
      "197 False 0.3529411764705882\n",
      "198 False 1.996078431372549\n",
      "199 False 11.254901960784311\n",
      "200 False 40.02352941176469\n",
      "201 False 118.3843137254902\n",
      "202 False 238.3215686274512\n",
      "203 False 427.6705882352951\n",
      "204 False 687.5843137254919\n",
      "205 False 1025.0000000000025\n",
      "206 False 1433.011764705888\n",
      "207 False 1831.117647058828\n",
      "208 False 2164.517647058831\n",
      "209 False 2452.4000000000115\n",
      "210 False 2614.2000000000103\n",
      "211 False 2682.596078431387\n",
      "212 False 2654.8901960784424\n",
      "213 False 2495.752941176486\n",
      "214 False 2215.95294117648\n",
      "215 False 1834.3843137254958\n",
      "216 False 1356.0901960784363\n",
      "217 False 918.2941176470614\n",
      "218 False 551.4235294117657\n",
      "219 False 298.67843137254954\n",
      "220 False 138.9019607843137\n",
      "221 False 48.83921568627452\n",
      "222 False 10.294117647058826\n",
      "223 False 0.37254901960784315\n",
      "224 True 0.0\n",
      "225 False 2.423529411764706\n",
      "226 False 5.392156862745097\n",
      "227 False 27.309803921568623\n",
      "228 False 72.78039215686282\n",
      "229 False 169.78039215686292\n",
      "230 False 311.7921568627458\n",
      "231 False 544.4039215686296\n",
      "232 False 863.0352941176479\n",
      "233 False 1302.0941176470633\n",
      "234 False 1752.1490196078485\n",
      "235 False 2115.109803921577\n",
      "236 False 2324.329411764711\n",
      "237 False 2424.8509803921684\n",
      "238 False 2453.6862745098133\n",
      "239 False 2416.7450980392273\n",
      "240 False 2398.2235294117722\n",
      "241 False 2373.2862745098137\n",
      "242 False 2265.588235294124\n",
      "243 False 1961.800000000007\n",
      "244 False 1520.9372549019636\n",
      "245 False 1047.035294117651\n",
      "246 False 613.1764705882365\n",
      "247 False 307.0941176470595\n",
      "248 False 141.36470588235292\n",
      "249 False 49.41960784313725\n",
      "250 False 11.372549019607844\n",
      "251 True 0.0\n",
      "252 True 0.0\n",
      "253 False 2.984313725490196\n",
      "254 False 14.074509803921567\n",
      "255 False 36.64313725490196\n",
      "256 False 87.66666666666666\n",
      "257 False 196.02352941176483\n",
      "258 False 371.0470588235304\n",
      "259 False 628.52549019608\n",
      "260 False 1024.9607843137278\n",
      "261 False 1484.670588235299\n",
      "262 False 1896.7725490196153\n",
      "263 False 2128.1803921568708\n",
      "264 False 2137.7921568627517\n",
      "265 False 2066.2196078431452\n",
      "266 False 1960.3333333333414\n",
      "267 False 1952.1607843137313\n",
      "268 False 2008.3843137254953\n",
      "269 False 2127.25098039217\n",
      "270 False 2165.611764705892\n",
      "271 False 1962.9490196078502\n",
      "272 False 1526.6509803921622\n",
      "273 False 1045.2784313725524\n",
      "274 False 606.6235294117649\n",
      "275 False 286.7098039215688\n",
      "276 False 110.43921568627455\n",
      "277 False 37.8156862745098\n",
      "278 False 9.839215686274509\n",
      "279 False 1.4980392156862745\n",
      "280 True 0.0\n",
      "281 False 3.811764705882353\n",
      "282 False 13.627450980392155\n",
      "283 False 34.43529411764706\n",
      "284 False 82.98823529411763\n",
      "285 False 190.60392156862758\n",
      "286 False 379.95294117647154\n",
      "287 False 692.2117647058847\n",
      "288 False 1115.8039215686315\n",
      "289 False 1576.4862745098083\n",
      "290 False 1921.341176470594\n",
      "291 False 2002.4235294117723\n",
      "292 False 1830.2274509803976\n",
      "293 False 1672.180392156867\n",
      "294 False 1571.2392156862786\n",
      "295 False 1638.4274509803943\n",
      "296 False 1790.4235294117675\n",
      "297 False 2002.752941176476\n",
      "298 False 2086.3137254902044\n",
      "299 False 1857.58039215687\n",
      "300 False 1423.556862745106\n",
      "301 False 953.7333333333363\n",
      "302 False 553.980392156864\n",
      "303 False 235.83921568627477\n",
      "304 False 77.67058823529416\n",
      "305 False 18.44313725490196\n",
      "306 False 3.2862745098039214\n",
      "307 False 0.2901960784313726\n",
      "308 True 0.0\n",
      "309 False 2.380392156862745\n",
      "310 False 10.666666666666664\n",
      "311 False 30.215686274509803\n",
      "312 False 74.22352941176474\n",
      "313 False 180.04313725490206\n",
      "314 False 399.9372549019614\n",
      "315 False 755.6039215686291\n",
      "316 False 1228.0705882352984\n",
      "317 False 1675.1176470588266\n",
      "318 False 1919.8549019607917\n",
      "319 False 1857.8078431372637\n",
      "320 False 1617.6745098039285\n",
      "321 False 1467.4000000000026\n",
      "322 False 1512.1137254902005\n",
      "323 False 1670.537254901969\n",
      "324 False 1888.2784313725542\n",
      "325 False 2096.2117647058913\n",
      "326 False 2071.7333333333418\n",
      "327 False 1746.1803921568674\n",
      "328 False 1271.0431372549072\n",
      "329 False 822.7882352941203\n",
      "330 False 484.9607843137268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331 False 221.85882352941204\n",
      "332 False 64.04705882352941\n",
      "333 False 6.572549019607844\n",
      "334 False 1.5529411764705885\n",
      "335 True 0.0\n",
      "336 False 0.2549019607843137\n",
      "337 False 1.5999999999999999\n",
      "338 False 6.047058823529412\n",
      "339 False 17.33333333333333\n",
      "340 False 62.121568627451026\n",
      "341 False 185.83137254901976\n",
      "342 False 438.2941176470599\n",
      "343 False 827.5058823529433\n",
      "344 False 1335.4549019607875\n",
      "345 False 1757.7882352941226\n",
      "346 False 1921.462745098048\n",
      "347 False 1802.3803921568676\n",
      "348 False 1600.6823529411797\n",
      "349 False 1574.3843137254942\n",
      "350 False 1754.192156862748\n",
      "351 False 2002.3450980392251\n",
      "352 False 2222.886274509815\n",
      "353 False 2306.6823529411927\n",
      "354 False 2098.772549019618\n",
      "355 False 1633.9333333333395\n",
      "356 False 1158.149019607847\n",
      "357 False 758.4274509803947\n",
      "358 False 458.945098039217\n",
      "359 False 228.15686274509852\n",
      "360 False 71.82745098039216\n",
      "361 False 5.780392156862747\n",
      "362 False 1.3333333333333335\n",
      "363 True 0.0\n",
      "364 False 0.12549019607843137\n",
      "365 False 0.41960784313725485\n",
      "366 False 2.1176470588235294\n",
      "367 False 9.062745098039215\n",
      "368 False 61.3529411764706\n",
      "369 False 207.12549019607874\n",
      "370 False 486.8666666666682\n",
      "371 False 917.7058823529437\n",
      "372 False 1415.5568627451023\n",
      "373 False 1787.6039215686353\n",
      "374 False 1884.2352941176528\n",
      "375 False 1811.1411764705977\n",
      "376 False 1741.7843137254956\n",
      "377 False 1917.749019607848\n",
      "378 False 2172.9411764705997\n",
      "379 False 2435.8588235294287\n",
      "380 False 2555.11764705884\n",
      "381 False 2489.725490196092\n",
      "382 False 2116.007843137263\n",
      "383 False 1585.3333333333362\n",
      "384 False 1114.0470588235328\n",
      "385 False 755.5294117647078\n",
      "386 False 472.3607843137272\n",
      "387 False 253.38823529411815\n",
      "388 False 82.41176470588232\n",
      "389 False 5.094117647058824\n",
      "390 True 0.0\n",
      "391 True 0.0\n",
      "392 True 0.0\n",
      "393 True 0.0\n",
      "394 False 1.6705882352941177\n",
      "395 False 8.96078431372549\n",
      "396 False 75.764705882353\n",
      "397 False 246.5294117647064\n",
      "398 False 548.8431372549035\n",
      "399 False 978.6078431372589\n",
      "400 False 1438.6901960784355\n",
      "401 False 1761.913725490202\n",
      "402 False 1851.4352941176555\n",
      "403 False 1838.8823529411864\n",
      "404 False 1908.1019607843157\n",
      "405 False 2256.176470588245\n",
      "406 False 2554.250980392172\n",
      "407 False 2738.4392156862837\n",
      "408 False 2673.71372549021\n",
      "409 False 2512.2078431372706\n",
      "410 False 2089.3764705882445\n",
      "411 False 1562.8509803921588\n",
      "412 False 1127.2901960784354\n",
      "413 False 797.1568627450998\n",
      "414 False 501.68235294117744\n",
      "415 False 265.08235294117696\n",
      "416 False 90.22352941176473\n",
      "417 False 7.270588235294118\n",
      "418 True 0.0\n",
      "419 True 0.0\n",
      "420 True 0.0\n",
      "421 True 0.0\n",
      "422 False 1.1411764705882352\n",
      "423 False 9.792156862745099\n",
      "424 False 82.98039215686275\n",
      "425 False 287.98431372549044\n",
      "426 False 605.0666666666682\n",
      "427 False 998.7019607843183\n",
      "428 False 1404.7411764705937\n",
      "429 False 1673.0666666666714\n",
      "430 False 1778.7960784313773\n",
      "431 False 1837.894117647063\n",
      "432 False 2053.105882352951\n",
      "433 False 2437.5411764705977\n",
      "434 False 2696.4941176470757\n",
      "435 False 2752.529411764719\n",
      "436 False 2562.9058823529476\n",
      "437 False 2374.274509803933\n",
      "438 False 1983.5176470588308\n",
      "439 False 1526.1960784313794\n",
      "440 False 1156.831372549022\n",
      "441 False 832.3490196078462\n",
      "442 False 523.0627450980396\n",
      "443 False 271.58039215686335\n",
      "444 False 92.47058823529412\n",
      "445 False 12.999999999999996\n",
      "446 False 1.8196078431372549\n",
      "447 False 0.023529411764705882\n",
      "448 True 0.0\n",
      "449 True 0.0\n",
      "450 False 2.156862745098039\n",
      "451 False 11.19607843137255\n",
      "452 False 94.36470588235296\n",
      "453 False 334.6745098039224\n",
      "454 False 633.5647058823552\n",
      "455 False 965.3843137254935\n",
      "456 False 1300.349019607847\n",
      "457 False 1533.8431372549064\n",
      "458 False 1656.533333333339\n",
      "459 False 1732.1294117647087\n",
      "460 False 1963.4352941176548\n",
      "461 False 2270.2196078431466\n",
      "462 False 2474.831372549037\n",
      "463 False 2500.3686274509887\n",
      "464 False 2389.160784313736\n",
      "465 False 2211.8156862745195\n",
      "466 False 1863.4392156862802\n",
      "467 False 1511.4980392156904\n",
      "468 False 1174.6313725490243\n",
      "469 False 840.2588235294146\n",
      "470 False 516.6784313725501\n",
      "471 False 264.2941176470591\n",
      "472 False 91.45098039215688\n",
      "473 False 16.93333333333333\n",
      "474 False 2.6392156862745098\n",
      "475 False 0.043137254901960784\n",
      "476 True 0.0\n",
      "477 False 0.2784313725490196\n",
      "478 False 2.776470588235294\n",
      "479 False 16.79215686274509\n",
      "480 False 122.57647058823532\n",
      "481 False 364.36470588235323\n",
      "482 False 656.1411764705894\n",
      "483 False 929.8745098039237\n",
      "484 False 1174.79215686275\n",
      "485 False 1368.000000000004\n",
      "486 False 1484.8078431372574\n",
      "487 False 1583.9098039215717\n",
      "488 False 1748.6431372549073\n",
      "489 False 1995.921568627459\n",
      "490 False 2179.074509803931\n",
      "491 False 2260.8196078431447\n",
      "492 False 2235.5882352941276\n",
      "493 False 2067.5686274509903\n",
      "494 False 1803.094117647063\n",
      "495 False 1487.8117647058857\n",
      "496 False 1163.7372549019663\n",
      "497 False 802.7843137254924\n",
      "498 False 469.13725490196174\n",
      "499 False 223.4666666666669\n",
      "500 False 86.52549019607845\n",
      "501 False 26.95686274509804\n",
      "502 False 3.6784313725490194\n",
      "503 False 0.043137254901960784\n",
      "504 True 0.0\n",
      "505 False 0.07058823529411765\n",
      "506 False 1.7411764705882353\n",
      "507 False 26.729411764705873\n",
      "508 False 161.58039215686287\n",
      "509 False 419.01176470588297\n",
      "510 False 681.9764705882367\n",
      "511 False 937.4745098039244\n",
      "512 False 1120.8000000000063\n",
      "513 False 1307.1647058823576\n",
      "514 False 1407.9098039215733\n",
      "515 False 1495.4980392156926\n",
      "516 False 1649.7764705882432\n",
      "517 False 1885.0666666666743\n",
      "518 False 2074.7568627451055\n",
      "519 False 2190.509803921579\n",
      "520 False 2208.2000000000085\n",
      "521 False 2106.2274509804015\n",
      "522 False 1847.384313725497\n",
      "523 False 1476.13333333334\n",
      "524 False 1106.5294117647086\n",
      "525 False 737.5372549019628\n",
      "526 False 426.65490196078537\n",
      "527 False 198.43529411764717\n",
      "528 False 76.88627450980393\n",
      "529 False 28.65490196078432\n",
      "530 False 4.133333333333334\n",
      "531 False 0.01568627450980392\n",
      "532 True 0.0\n",
      "533 False 0.3803921568627451\n",
      "534 False 4.635294117647059\n",
      "535 False 37.30980392156862\n",
      "536 False 185.96078431372555\n",
      "537 False 458.2039215686286\n",
      "538 False 733.5137254901982\n",
      "539 False 1006.533333333336\n",
      "540 False 1215.2901960784368\n",
      "541 False 1400.4705882352969\n",
      "542 False 1522.9490196078484\n",
      "543 False 1616.792156862754\n",
      "544 False 1788.9764705882428\n",
      "545 False 2006.8392156862822\n",
      "546 False 2203.6156862745215\n",
      "547 False 2345.9568627451076\n",
      "548 False 2332.8549019607963\n",
      "549 False 2156.411764705892\n",
      "550 False 1816.3882352941237\n",
      "551 False 1397.3137254901978\n",
      "552 False 987.2352941176495\n",
      "553 False 640.4000000000023\n",
      "554 False 360.47843137254966\n",
      "555 False 163.05882352941197\n",
      "556 False 63.99215686274513\n",
      "557 False 21.043137254901954\n",
      "558 False 6.1686274509803924\n",
      "559 True 0.0\n",
      "560 True 0.0\n",
      "561 True 0.0\n",
      "562 False 6.129411764705883\n",
      "563 False 46.231372549019596\n",
      "564 False 178.25098039215692\n",
      "565 False 440.3764705882358\n",
      "566 False 736.6117647058836\n",
      "567 False 1059.4941176470636\n",
      "568 False 1346.1803921568703\n",
      "569 False 1600.6235294117694\n",
      "570 False 1786.1058823529486\n",
      "571 False 1929.58039215687\n",
      "572 False 2110.078431372558\n",
      "573 False 2318.086274509817\n",
      "574 False 2483.011764705892\n",
      "575 False 2491.2666666666873\n",
      "576 False 2355.11372549021\n",
      "577 False 2047.3176470588292\n",
      "578 False 1633.5411764705966\n",
      "579 False 1156.8627450980432\n",
      "580 False 779.8117647058849\n",
      "581 False 493.3215686274522\n",
      "582 False 256.6862745098043\n",
      "583 False 118.40784313725491\n",
      "584 False 47.34901960784314\n",
      "585 False 12.29019607843137\n",
      "586 False 5.35686274509804\n",
      "587 True 0.0\n",
      "588 True 0.0\n",
      "589 True 0.0\n",
      "590 False 8.639215686274508\n",
      "591 False 45.160784313725514\n",
      "592 False 144.64313725490211\n",
      "593 False 362.9490196078441\n",
      "594 False 657.9607843137269\n",
      "595 False 1009.4745098039249\n",
      "596 False 1371.5921568627505\n",
      "597 False 1717.1607843137326\n",
      "598 False 1992.4549019607914\n",
      "599 False 2211.8784313725596\n",
      "600 False 2416.192156862758\n",
      "601 False 2581.5215686274655\n",
      "602 False 2593.721568627465\n",
      "603 False 2462.105882352951\n",
      "604 False 2173.4274509804004\n",
      "605 False 1743.4549019607878\n",
      "606 False 1273.6196078431412\n",
      "607 False 843.1882352941191\n",
      "608 False 539.1372549019625\n",
      "609 False 306.45098039215725\n",
      "610 False 152.20392156862752\n",
      "611 False 77.16078431372553\n",
      "612 False 35.38431372549021\n",
      "613 False 8.498039215686273\n",
      "614 False 1.4549019607843137\n",
      "615 True 0.0\n",
      "616 True 0.0\n",
      "617 True 0.0\n",
      "618 False 5.509803921568627\n",
      "619 False 26.03529411764706\n",
      "620 False 83.38823529411768\n",
      "621 False 233.5215686274512\n",
      "622 False 482.9450980392163\n",
      "623 False 808.0431372549033\n",
      "624 False 1199.8705882352976\n",
      "625 False 1586.1098039215724\n",
      "626 False 1959.6078431372634\n",
      "627 False 2221.8039215686413\n",
      "628 False 2406.6039215686415\n",
      "629 False 2465.027450980408\n",
      "630 False 2370.2274509804\n",
      "631 False 2112.8117647058903\n",
      "632 False 1717.5803921568681\n",
      "633 False 1276.4470588235336\n",
      "634 False 854.8549019607856\n",
      "635 False 527.0745098039232\n",
      "636 False 310.99607843137306\n",
      "637 False 167.0039215686275\n",
      "638 False 88.34901960784313\n",
      "639 False 45.29803921568628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640 False 19.24313725490196\n",
      "641 False 3.537254901960784\n",
      "642 False 0.043137254901960784\n",
      "643 True 0.0\n",
      "644 True 0.0\n",
      "645 True 0.0\n",
      "646 False 0.8352941176470589\n",
      "647 False 10.16470588235294\n",
      "648 False 36.20392156862746\n",
      "649 False 107.86274509803924\n",
      "650 False 263.69411764705916\n",
      "651 False 490.2784313725499\n",
      "652 False 820.3215686274523\n",
      "653 False 1169.6980392156902\n",
      "654 False 1509.9921568627497\n",
      "655 False 1797.2588235294193\n",
      "656 False 1961.988235294128\n",
      "657 False 1946.9843137254993\n",
      "658 False 1773.239215686278\n",
      "659 False 1468.6745098039255\n",
      "660 False 1122.6823529411793\n",
      "661 False 771.9568627451004\n",
      "662 False 472.15294117647113\n",
      "663 False 273.3333333333335\n",
      "664 False 151.87450980392177\n",
      "665 False 84.63921568627454\n",
      "666 False 43.29411764705883\n",
      "667 False 22.552941176470583\n",
      "668 False 7.0705882352941165\n",
      "669 False 1.8627450980392157\n",
      "670 True 0.0\n",
      "671 True 0.0\n",
      "672 True 0.0\n",
      "673 True 0.0\n",
      "674 False 0.03529411764705882\n",
      "675 False 1.525490196078431\n",
      "676 False 12.51764705882353\n",
      "677 False 35.43921568627453\n",
      "678 False 95.18431372549027\n",
      "679 False 201.56470588235305\n",
      "680 False 351.0941176470597\n",
      "681 False 536.0941176470601\n",
      "682 False 735.5333333333342\n",
      "683 False 910.0039215686294\n",
      "684 False 996.533333333336\n",
      "685 False 979.4862745098061\n",
      "686 False 881.9843137254923\n",
      "687 False 705.5882352941177\n",
      "688 False 526.5647058823539\n",
      "689 False 378.9490196078436\n",
      "690 False 229.72156862745135\n",
      "691 False 124.0745098039216\n",
      "692 False 66.99607843137258\n",
      "693 False 35.73333333333334\n",
      "694 False 18.380392156862744\n",
      "695 False 10.247058823529413\n",
      "696 False 3.3843137254901965\n",
      "697 False 1.3882352941176472\n",
      "698 False 0.3843137254901961\n",
      "699 True 0.0\n",
      "700 True 0.0\n",
      "701 True 0.0\n",
      "702 True 0.0\n",
      "703 True 0.0\n",
      "704 False 2.9098039215686278\n",
      "705 False 10.101960784313723\n",
      "706 False 32.39999999999999\n",
      "707 False 66.33333333333333\n",
      "708 False 122.30980392156866\n",
      "709 False 188.2745098039217\n",
      "710 False 259.46666666666704\n",
      "711 False 318.62745098039255\n",
      "712 False 342.69803921568706\n",
      "713 False 332.5882352941184\n",
      "714 False 296.325490196079\n",
      "715 False 265.51372549019646\n",
      "716 False 211.7294117647061\n",
      "717 False 165.8078431372552\n",
      "718 False 103.52941176470594\n",
      "719 False 55.36862745098042\n",
      "720 False 30.290196078431375\n",
      "721 False 13.109803921568627\n",
      "722 False 6.415686274509804\n",
      "723 False 3.8509803921568633\n",
      "724 False 0.1843137254901961\n",
      "725 False 0.3411764705882353\n",
      "726 False 0.40784313725490196\n",
      "727 True 0.0\n",
      "728 True 0.0\n",
      "729 True 0.0\n",
      "730 True 0.0\n",
      "731 True 0.0\n",
      "732 False 0.08627450980392157\n",
      "733 False 1.258823529411765\n",
      "734 False 6.40392156862745\n",
      "735 False 16.999999999999996\n",
      "736 False 36.64313725490197\n",
      "737 False 60.96078431372546\n",
      "738 False 86.74117647058829\n",
      "739 False 113.58431372549018\n",
      "740 False 124.4901960784314\n",
      "741 False 118.46666666666671\n",
      "742 False 112.70196078431377\n",
      "743 False 88.98039215686269\n",
      "744 False 66.08235294117647\n",
      "745 False 53.960784313725505\n",
      "746 False 32.30980392156862\n",
      "747 False 15.949019607843134\n",
      "748 False 8.858823529411765\n",
      "749 False 4.4941176470588236\n",
      "750 False 2.0274509803921568\n",
      "751 False 0.5490196078431373\n",
      "752 True 0.0\n",
      "753 True 0.0\n",
      "754 True 0.0\n",
      "755 True 0.0\n",
      "756 True 0.0\n",
      "757 True 0.0\n",
      "758 True 0.0\n",
      "759 True 0.0\n",
      "760 True 0.0\n",
      "761 False 0.2235294117647059\n",
      "762 False 0.9607843137254902\n",
      "763 False 1.0666666666666667\n",
      "764 False 1.9176470588235295\n",
      "765 False 5.662745098039216\n",
      "766 False 8.91764705882353\n",
      "767 False 8.992156862745098\n",
      "768 False 8.215686274509803\n",
      "769 False 7.807843137254901\n",
      "770 False 10.396078431372548\n",
      "771 False 10.278431372549019\n",
      "772 False 8.827450980392156\n",
      "773 False 5.454901960784314\n",
      "774 False 5.164705882352941\n",
      "775 False 1.862745098039216\n",
      "776 False 0.058823529411764705\n",
      "777 False 0.043137254901960784\n",
      "778 False 0.6039215686274509\n",
      "779 True 0.0\n",
      "780 True 0.0\n",
      "781 True 0.0\n",
      "782 True 0.0\n",
      "783 True 0.0\n"
     ]
    }
   ],
   "source": [
    "# To see the sum of these values\n",
    "for i in range(784):\n",
    "    s = 0\n",
    "    for t in train_data:\n",
    "        s += t[i]\n",
    "\n",
    "    print(i, res[i], s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the above function works to find these useless features.  We now only need to remove those features from the data sets and note the indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  52,  53,  54,  55,\n",
      "        56,  57,  58,  59,  82,  83,  84,  85,  86,  87, 110, 111, 112,\n",
      "       113, 114, 139, 140, 141, 142, 167, 168, 196, 224, 251, 252, 280,\n",
      "       308, 335, 363, 390, 391, 392, 393, 418, 419, 420, 421, 448, 449,\n",
      "       476, 504, 532, 559, 560, 561, 587, 588, 589, 615, 616, 617, 643,\n",
      "       644, 645, 670, 671, 672, 673, 699, 700, 701, 702, 703, 727, 728,\n",
      "       729, 730, 731, 752, 753, 754, 755, 756, 757, 758, 759, 760, 779,\n",
      "       780, 781, 782, 783]),)\n"
     ]
    }
   ],
   "source": [
    "res = np.all(train_data == train_data[0,:], axis = 0)\n",
    "removable_indices = np.where(res)\n",
    "print(removable_indices) # indices of useless features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n",
      "(50000, 663)\n"
     ]
    }
   ],
   "source": [
    "clean_train_data = np.delete(train_data, removable_indices, 1)\n",
    "print(train_data.shape)\n",
    "print(clean_train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how we removed columns from the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n",
      "(50000, 663)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(clean_train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True  True  True  True  True  True  True  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False  True  True\n",
      "  True  True  True  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False  True  True  True  True  True False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False  True  True  True  True False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False  True\n",
      "  True False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False  True\n",
      "  True False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False  True  True  True  True False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False  True  True\n",
      "  True  True False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True  True False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False  True  True  True False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False  True\n",
      "  True  True False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False  True  True  True False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False  True  True  True False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False  True  True\n",
      "  True  True False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False  True  True  True  True  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False  True  True  True  True  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False  True  True  True  True\n",
      "  True  True  True  True  True False False False False False False False\n",
      " False False False False False False False False False False False  True\n",
      "  True  True  True  True]\n",
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False]\n"
     ]
    }
   ],
   "source": [
    "res_train_data = np.all(train_data == train_data[0,:], axis = 0)\n",
    "print(res_train_data)\n",
    "\n",
    "res_clean_data = np.all(clean_train_data == clean_train_data[0,:], axis = 0)\n",
    "print(res_clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(sum(res_train_data))\n",
    "print(sum(res_clean_data)) #should be 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we implement this into the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnScript import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Features (array([ 12,  13,  14,  15,  32,  33,  34,  35,  36,  37,  38,  39,  40,\n",
      "        41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  58,  59,\n",
      "        60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,\n",
      "        73,  74,  75,  76,  77,  78,  79,  80,  81,  86,  87,  88,  89,\n",
      "        90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102,\n",
      "       103, 104, 105, 106, 107, 108, 109, 110, 113, 114, 115, 116, 117,\n",
      "       118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
      "       131, 132, 133, 134, 135, 136, 137, 138, 139, 142, 143, 144, 145,\n",
      "       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
      "       159, 160, 161, 162, 163, 164, 165, 166, 167, 169, 170, 171, 172,\n",
      "       173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185,\n",
      "       186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198,\n",
      "       199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "       212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224,\n",
      "       225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "       238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250,\n",
      "       251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
      "       264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276,\n",
      "       277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289,\n",
      "       290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302,\n",
      "       303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315,\n",
      "       316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328,\n",
      "       329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341,\n",
      "       342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354,\n",
      "       355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "       368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380,\n",
      "       381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393,\n",
      "       394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
      "       407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "       420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432,\n",
      "       433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445,\n",
      "       446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458,\n",
      "       459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471,\n",
      "       472, 473, 474, 475, 477, 478, 479, 480, 481, 482, 483, 484, 485,\n",
      "       486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498,\n",
      "       499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511,\n",
      "       512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524,\n",
      "       525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537,\n",
      "       538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550,\n",
      "       551, 552, 553, 554, 555, 556, 557, 558, 559, 561, 562, 563, 564,\n",
      "       565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577,\n",
      "       578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590,\n",
      "       591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603,\n",
      "       604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616,\n",
      "       617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629,\n",
      "       630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642,\n",
      "       643, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657,\n",
      "       658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670,\n",
      "       674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686,\n",
      "       687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 702,\n",
      "       703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715,\n",
      "       716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 731, 732,\n",
      "       733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745,\n",
      "       746, 747, 748, 749, 750, 751, 752, 753, 760, 761, 762, 763, 764,\n",
      "       765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777,\n",
      "       778, 779]),)\n",
      "preprocess done\n"
     ]
    }
   ],
   "source": [
    "train_data, train_label, validation_data, validation_label, test_data, test_label = preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 717)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n"
     ]
    }
   ],
   "source": [
    "res = np.all(train_data == train_data[0,:], axis = 0)\n",
    "print(sum(res))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And it seems to work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nnObjFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnScript import preprocess, sigmoid, initializeWeights\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Features (array([ 12,  13,  14,  15,  32,  33,  34,  35,  36,  37,  38,  39,  40,\n",
      "        41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  58,  59,\n",
      "        60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,\n",
      "        73,  74,  75,  76,  77,  78,  79,  80,  81,  86,  87,  88,  89,\n",
      "        90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102,\n",
      "       103, 104, 105, 106, 107, 108, 109, 110, 113, 114, 115, 116, 117,\n",
      "       118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
      "       131, 132, 133, 134, 135, 136, 137, 138, 139, 142, 143, 144, 145,\n",
      "       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
      "       159, 160, 161, 162, 163, 164, 165, 166, 167, 169, 170, 171, 172,\n",
      "       173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185,\n",
      "       186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198,\n",
      "       199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
      "       212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224,\n",
      "       225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "       238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250,\n",
      "       251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
      "       264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276,\n",
      "       277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289,\n",
      "       290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302,\n",
      "       303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315,\n",
      "       316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328,\n",
      "       329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341,\n",
      "       342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354,\n",
      "       355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "       368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380,\n",
      "       381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393,\n",
      "       394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
      "       407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "       420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432,\n",
      "       433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445,\n",
      "       446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458,\n",
      "       459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471,\n",
      "       472, 473, 474, 475, 477, 478, 479, 480, 481, 482, 483, 484, 485,\n",
      "       486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498,\n",
      "       499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511,\n",
      "       512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524,\n",
      "       525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537,\n",
      "       538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550,\n",
      "       551, 552, 553, 554, 555, 556, 557, 558, 559, 561, 562, 563, 564,\n",
      "       565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577,\n",
      "       578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 589, 590, 591,\n",
      "       592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604,\n",
      "       605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 617, 618, 619,\n",
      "       620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632,\n",
      "       633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 646, 647, 648,\n",
      "       649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661,\n",
      "       662, 663, 664, 665, 666, 667, 668, 669, 670, 674, 675, 676, 677,\n",
      "       678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690,\n",
      "       691, 692, 693, 694, 695, 696, 697, 698, 702, 703, 704, 705, 706,\n",
      "       707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719,\n",
      "       720, 721, 722, 723, 724, 725, 726, 732, 733, 734, 735, 736, 737,\n",
      "       738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750,\n",
      "       751, 752, 753, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769,\n",
      "       770, 771, 772, 773, 774, 775, 776, 777, 778, 779]),)\n",
      "preprocess done\n"
     ]
    }
   ],
   "source": [
    "train_data, train_label, validation_data, validation_label, test_data, test_label = preprocess()\n",
    "\n",
    "#  Train Neural Network\n",
    "\n",
    "# set the number of nodes in input unit (not including bias unit)\n",
    "n_input = train_data.shape[1]\n",
    "\n",
    "# set the number of nodes in hidden unit (not including bias unit)\n",
    "n_hidden = 50\n",
    "\n",
    "# set the number of nodes in output unit\n",
    "n_class = 10\n",
    "\n",
    "# initialize the weights into some random matrices\n",
    "initial_w1 = initializeWeights(n_input, n_hidden)\n",
    "initial_w2 = initializeWeights(n_hidden, n_class)\n",
    "\n",
    "# unroll 2 weight matrices into single column vector\n",
    "initialWeights = np.concatenate((initial_w1.flatten(), initial_w2.flatten()), 0)\n",
    "\n",
    "# set the regularization hyper-parameter\n",
    "lambdaval = 0\n",
    "\n",
    "args = (n_input, n_hidden, n_class, train_data, train_label, lambdaval)\n",
    "\n",
    "# Train Neural Network using fmin_cg or minimize from scipy,optimize module. Check documentation for a working example\n",
    "\n",
    "opts = {'maxiter': 50}  # Preferred value.\n",
    "\n",
    "#nn_params = minimize(nnObjFunction, initialWeights, jac=True, args=args, method='CG', options=opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nnObjFunction(params, *args):\n",
    "    n_input, n_hidden, n_class, training_data, training_label, lambdaval = args\n",
    "\n",
    "    w1 = params[0:n_hidden * (n_input + 1)].reshape((n_hidden, (n_input + 1)))\n",
    "    w2 = params[(n_hidden * (n_input + 1)):].reshape((n_class, (n_hidden + 1)))\n",
    "    obj_val = 0\n",
    "\n",
    "    # Your code here\n",
    "    \n",
    "    # Set Bias\n",
    "    np.append(np.array([[1,2,3], [1,1,1], [2,2,2]]), np.ones((3,1)), 1)\n",
    "    \n",
    "    b1 = np.ones((len(training_data), 1))\n",
    "    b2 = np.ones((len(training_data), 1))\n",
    "\n",
    "    # Forward Propagation\n",
    "    X = np.append(training_data, b1, 1) # append bias\n",
    "    net1 = X.dot(w1.T)\n",
    "    o1 = sigmoid(net1)\n",
    "    \n",
    "    H = np.append(net1, b2, 1)\n",
    "    net2 = H.dot(w2.T)\n",
    "    o2 = sigmoid(net2)\n",
    "    \n",
    "    # 1-hot encoding\n",
    "    y = np.zeros(o2.shape)\n",
    "    y[np.arange(o2.shape[0]), train_label.astype(int)] = 1\n",
    "    \n",
    "    # Error\n",
    "    E = (y*np.log(o2) + (np.ones(y.shape) - y)*np.log(np.ones(o2.shape) - o2))\n",
    "    obj_val = -(np.sum(E) / len(training_data))\n",
    "    \n",
    "    # Gradients\n",
    "    grad_w2 = o2*(o2-y)\n",
    "    grad_w1 = np.zeros(w1.shape)\n",
    "    \n",
    "    # Make sure you reshape the gradient matrices to a 1D array. for instance if your gradient matrices are grad_w1 and grad_w2\n",
    "    # you would use code similar to the one below to create a flat array\n",
    "    obj_grad = np.concatenate((grad_w1.flatten(), grad_w2.flatten()),0)\n",
    "    print(grad_w2.shape)\n",
    "    print(grad_w1.shape)\n",
    "    print(obj_grad.shape)\n",
    "    #obj_grad = np.array([])\n",
    "\n",
    "    return (obj_val, obj_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8.213019694139337, array([0. , 0. , 0. , ..., 0.1, 0.1, 0.1]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnObjFunction(initialWeights, *args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 51)\n",
      "(50, 713)\n"
     ]
    }
   ],
   "source": [
    "print(initial_w2.shape)\n",
    "print(initial_w1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n",
      "(10, 51)\n",
      "(50, 713)\n",
      "(36160,)\n"
     ]
    }
   ],
   "source": [
    "nn_params = minimize(nnObjFunction, initialWeights, jac=True, args=args, method='CG', options=opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 8.213019694139337\n",
       "     jac: array([0. , 0. , 0. , ..., 0.1, 0.1, 0.1])\n",
       " message: 'Desired error not necessarily achieved due to precision loss.'\n",
       "    nfev: 95\n",
       "     nit: 0\n",
       "    njev: 83\n",
       "  status: 2\n",
       " success: False\n",
       "       x: array([-0.07195695,  0.08258197,  0.07292078, ...,  0.04886368,\n",
       "       -0.21037462,  0.29325883])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.07195695,  0.08258197,  0.07292078, ...,  0.04886368,\n",
       "       -0.21037462,  0.29325883])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
